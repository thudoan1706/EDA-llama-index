{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from orchestrator.ingestion.vector_store.pinecone.client import PineconeClient\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Event,\n",
    "    step,\n",
    ")\n",
    "from orchestrator.ingestion.utils.pdf_processor import process_pdfs_in_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events.py\n",
    "class InitializeEvent(Event):\n",
    "    pass\n",
    "\n",
    "class ConciergeEvent(Event):\n",
    "    request: Optional[str]\n",
    "    just_completed: Optional[str]\n",
    "    need_help: Optional[bool]\n",
    "\n",
    "class OrchestratorEvent(Event):\n",
    "    request: Optional[str] = None\n",
    "\n",
    "class PDFIngestionEvent(Event):\n",
    "    request: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowSteps:\n",
    "    \n",
    "    @step(pass_context=True)\n",
    "    async def concierge(self, ctx: Context, ev: ConciergeEvent | StartEvent) -> InitializeEvent | StopEvent | OrchestratorEvent | None:\n",
    "        if isinstance(ev, StartEvent):\n",
    "            dirname = ev.get(\"dirname\")\n",
    "            if dirname is not None:\n",
    "                ctx.data[\"dirname\"] = dirname\n",
    "                return OrchestratorEvent(request=\"ingest\")  # Trigger the OrchestratorEvent for ingestion\n",
    "\n",
    "            return InitializeEvent()\n",
    "\n",
    "        return StopEvent(result={\"index\": ctx.data[\"index\"]})\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def initialize(self, ctx: Context, ev: InitializeEvent) -> ConciergeEvent:\n",
    "        ctx.data[\"index\"] = PineconeClient(collection_name=\"pdf-docs\")\n",
    "        return ConciergeEvent()\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def orchestrator(self, ctx: Context, ev: OrchestratorEvent) -> ConciergeEvent | PDFIngestionEvent | StopEvent:\n",
    "        if ev.request == \"ingest\":\n",
    "            return PDFIngestionEvent(request=\"start_pdf_ingestion\")\n",
    "        return StopEvent(result={\"message\": \"Orchestrator did not recognize the event\"})\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def ingest(self, ctx: Context, ev: PDFIngestionEvent) -> InitializeEvent | None:\n",
    "        dirname = ctx.data.get(\"dirname\")\n",
    "        if dirname:\n",
    "            nodes = process_pdfs_in_directory(dirname)\n",
    "\n",
    "            client = PineconeClient(collection_name=\"pdf-docs\")\n",
    "            client.upsert_indices(nodes)\n",
    "            ctx.data[\"dirname\"] = None\n",
    "            return InitializeEvent()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.py\n",
    "\n",
    "class ConciergeWorkflow(Workflow):\n",
    "    \n",
    "    steps = WorkflowSteps()\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def concierge(self, ctx: Context, ev: ConciergeEvent | StartEvent) -> InitializeEvent | StopEvent | OrchestratorEvent | None:\n",
    "        return await self.steps.concierge(ctx, ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def initialize(self, ctx: Context, ev: InitializeEvent) -> ConciergeEvent:\n",
    "        return await self.steps.initialize(ctx, ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def orchestrator(self, ctx: Context, ev: OrchestratorEvent) -> ConciergeEvent | PDFIngestionEvent | StopEvent:\n",
    "        return await self.steps.orchestrator(ctx, ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def ingest(self, ctx: Context, ev: PDFIngestionEvent) -> InitializeEvent | None:\n",
    "        return await self.steps.ingest(ctx, ev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concierge_flows.html\n",
      "Running step concierge\n",
      "Step concierge produced event InitializeEvent\n",
      "Running step initialize\n",
      "Step initialize produced event ConciergeEvent\n",
      "Running step concierge\n",
      "Step concierge produced event StopEvent\n",
      "{'index': <ingestion.vector_store.pinecone.client.PineconeClient object at 0x13f3c8c10>}\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "from workflow import ConciergeWorkflow\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(ConciergeWorkflow, filename=\"concierge_flows.html\")\n",
    "\n",
    "concierge = ConciergeWorkflow(timeout=180, verbose=True)\n",
    "result = await concierge.run()\n",
    "query_engine = result[\"index\"].index.as_query_engine()\n",
    "response = query_engine.query(\"how does Environmental difficulties at present are also challenging the sustainability of the Mediterranean way of living\")\n",
    "print(str(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Environmental difficulties at present are challenging the sustainability of the Mediterranean way of living through factors such as water scarcity, land degradation, and declining biodiversity. These challenges are exacerbated by issues like urbanization, pollution, soil erosion, and climate change, which impact water resources, agricultural productivity, and the overall ecosystem health in the Mediterranean regions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-llama-index-VIX4Qo5C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c9fee63db1833b128f9e0fcc88438d876a8dd4a4e8fdc61bea76064c0a94131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
