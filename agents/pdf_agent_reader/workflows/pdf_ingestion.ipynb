{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine\n",
    "from llama_index.core.postprocessor.llm_rerank import LLMRerank\n",
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Workflow,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    ")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from llama_index.core import Document\n",
    "\n",
    "class DocumentMetadata(BaseModel):\n",
    "    filename: str\n",
    "    page: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 194 documents from PDFs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from pydantic import BaseModel\n",
    "from llama_index.core import Document\n",
    "\n",
    "class DocumentMetadata(BaseModel):\n",
    "    filename: str\n",
    "    page: int\n",
    "\n",
    "def process_pdfs_in_directory(directory):\n",
    "    splitter = SentenceSplitter(\n",
    "        chunk_size=512,\n",
    "        chunk_overlap=30,\n",
    "    )\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with pdfplumber.open(filepath) as pdf:\n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    text = page.extract_text()\n",
    "                    if text:\n",
    "                        text_list = splitter.split_text(text)\n",
    "                        metadata = DocumentMetadata(filename=filename, page=page_num + 1)\n",
    "                        metadata_dict = metadata.dict()\n",
    "                        page_documents = [Document(text=t, \n",
    "                                                   metadata=metadata_dict, \n",
    "                                                   excluded_llm_metadata_keys=[\"filename\", \"page\"],\n",
    "                                                   excluded_embed_metadata_keys=[\"filename\", \"page\"]) \n",
    "                                          for t in text_list]\n",
    "                        documents.extend(page_documents)\n",
    "                        \n",
    "    return documents\n",
    "\n",
    "# Usage example:\n",
    "directory_path = \"../data/\"\n",
    "all_documents = process_pdfs_in_directory(directory_path)\n",
    "\n",
    "print(f\"Processed {len(all_documents)} documents from PDFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfIngestionWorkflow(Workflow):\n",
    "    @step(pass_context=True)\n",
    "    async def ingest(self, ctx: Context, ev: StartEvent) -> StopEvent | None:\n",
    "        \"\"\"Entry point to ingest a document, triggered by a StartEvent with `dirname`.\"\"\"\n",
    "        dirname = ev.get(\"dirname\")\n",
    "        if not dirname:\n",
    "            return None\n",
    "\n",
    "        documents = SimpleDirectoryReader(dirname).load_data()\n",
    "        ctx.data[\"index\"] = VectorStoreIndex.from_documents(\n",
    "            documents=documents,\n",
    "            embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "        )\n",
    "        return StopEvent(result=f\"Indexed {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda-llama-index-VIX4Qo5C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c9fee63db1833b128f9e0fcc88438d876a8dd4a4e8fdc61bea76064c0a94131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
